{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Vd8rvotTDeOF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDHn4t0ACk4c",
        "outputId": "54c29381-0e8c-48cc-ede1-c32b71d00224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-27 16:30:47--  https://raw.githubusercontent.com/soydz/ia-saberpro-prediction/main/data/train.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19229940 (18M) [application/zip]\n",
            "Saving to: ‚Äòtrain.zip‚Äô\n",
            "\n",
            "\rtrain.zip             0%[                    ]       0  --.-KB/s               \rtrain.zip           100%[===================>]  18.34M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-11-27 16:30:47 (339 MB/s) - ‚Äòtrain.zip‚Äô saved [19229940/19229940]\n",
            "\n",
            "--2025-11-27 16:30:47--  https://raw.githubusercontent.com/soydz/ia-saberpro-prediction/main/data/test.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7966338 (7.6M) [application/zip]\n",
            "Saving to: ‚Äòtest.zip‚Äô\n",
            "\n",
            "test.zip            100%[===================>]   7.60M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-11-27 16:30:47 (340 MB/s) - ‚Äòtest.zip‚Äô saved [7966338/7966338]\n",
            "\n",
            "Archive:  train.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.zip\n",
            "  inflating: test.csv                \n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/soydz/ia-saberpro-prediction/main/data/train.zip\n",
        "!wget https://raw.githubusercontent.com/soydz/ia-saberpro-prediction/main/data/test.zip\n",
        "!unzip train.zip\n",
        "!unzip test.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "print('train', train.shape)\n",
        "print('test', test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd9VmBi8DIjL",
        "outputId": "e2f7741b-3378-4f3d-cde2-5aced4a09fd6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train (692500, 21)\n",
            "test (296786, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Funciones"
      ],
      "metadata": {
        "id": "Vd8rvotTDeOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data_base_2(data):\n",
        "  data.drop(columns=['F_TIENEINTERNET.1', 'ID', 'PERIODO_ACADEMICO', 'E_PRIVADO_LIBERTAD'], inplace=True)\n",
        "\n",
        "  data['E_PRGM_ACADEMICO'] = data['E_PRGM_ACADEMICO'].apply(lambda x: unicodedata.normalize('NFKD', str(x)).encode('ASCII', 'ignore').decode('ASCII'))\n",
        "  data['E_PRGM_ACADEMICO'] = data['E_PRGM_ACADEMICO'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "  reemplazos = {\n",
        "    r'\\bADMINISTRACIN\\b': 'ADMINISTRACION',\n",
        "    r'\\bLOGSTICA\\b': 'LOGISTICA',\n",
        "    r'\\bPBLICA\\b': 'PUBLICA',\n",
        "    r'\\bGESTIN\\b': 'GESTION',\n",
        "    r'\\bQUMICA\\b': 'QUIMICA',\n",
        "    r'\\bFARMACUTICA\\b': 'FARMACEUTICA',\n",
        "    r'\\bGASTRONOMA\\b': 'GASTRONOMIA',\n",
        "    r'\\bPSICOSOCIALES\\b': 'PSICOSOCIALES',\n",
        "  }\n",
        "  data['E_PRGM_ACADEMICO']= data['E_PRGM_ACADEMICO'].replace(reemplazos, regex=True)\n",
        "\n",
        "  reemplazos = {\n",
        "    'MERCADEO':'ECONOMIA',\n",
        "    'MERCADEO NACIONAL E INTERNACIONAL':'ECONOMIA',\n",
        "    'MERCADEO Y VENTAS':'ECONOMIA',\n",
        "    'PROFESIONAL EN MERCADEO':'ECONOMIA',\n",
        "    'PROFESIONAL EN MERCADEO EMPRESARIAL':'ECONOMIA'\n",
        "  }\n",
        "  data['E_PRGM_ACADEMICO']= data['E_PRGM_ACADEMICO'].replace(reemplazos)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "jxSfS31di2bY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se agrupan los programas academicos segun la clasificaci√≥n del SNIES.\n",
        "El SNIES es el Sistema Nacional de Informaci√≥n de la Educaci√≥n Superior de Colombia.\n",
        "\n",
        "Definici√≥n de √°reas SNIES (agrupadas en 6 grupos)"
      ],
      "metadata": {
        "id": "q8Xec6ymsWTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "snies_areas = {\n",
        "  'SALUD': [\n",
        "    r'\\b(microbiolog[ia√≠]|bioan[√°a]lisis|gerontolog[ia√≠]|'\n",
        "    r'seguridad\\s+y\\s+salud\\s+(en\\s+el\\s+trabajo|para\\s+el\\s+trabajo))\\b',\n",
        "    r'\\b(medicina|enfermer[ia√≠]|odontolog[ia√≠]|fisioterapia|nutrici[√≥o]n|'\n",
        "    r'optometr[ia√≠]|bacteriolog[ia√≠]|fonoaudiolog[ia√≠]|psicolog[ia√≠]\\s+cl[i√≠]nica|'\n",
        "    r'terapia\\s+(ocupacional|cardiorrespiratoria|respiratoria)|instrumentaci[√≥o]n\\s+quir[u√∫]rgica|'\n",
        "    r'ciencias\\s+de\\s+la\\s+salud|salud\\s+p[√∫u]blica|salud\\s+ocupacional|'\n",
        "    r'bioquimica\\s+cl[i√≠]nica|microbiolog[ia√≠]\\s+y\\s+bioan[√°a]lisis|'\n",
        "    r'farmacia|gerontolog[ia√≠]|seguridad\\s+y\\s+salud\\s+en\\s+el\\s+trabajo)\\b',\n",
        "    r'\\bBACTERIOLOGIA\\b',\n",
        "    r'\\bFONOAUDIOLOGIA\\b',\n",
        "    r'\\bODONTOLOGIA\\b',\n",
        "    r'\\bOPTOMETRIA\\b',\n",
        "    r'\\bENFERMERIA\\b',\n",
        "    r'\\bMICROBIOLOG[√çI]A\\b',\n",
        "    r'\\bGERONTOLOG[√çI]A\\b',\n",
        "    r'TERAPIAS PSICOSOCIALES'\n",
        "  ],\n",
        "\n",
        "  'INGENIERIA': [\n",
        "    r'\\bINGENIERIA\\s+(ADMINISTRATIVA|AERONAUTICA|COMERCIAL|DE\\s+MERCADOS|'\n",
        "    r'DE\\s+PETROLEO\\s+Y\\s+GAS|DE\\s+PROCESOS(\\s+INDUSTRIALES)?|'\n",
        "    r'DE\\s+PRODUCCION(\\s+ACUICOLA)?|DE\\s+PRODUCTIVIDAD\\s+Y\\s+CALIDAD|'\n",
        "    r'DE\\s+TELECOMUNICACIONES|EN\\s+(ENERG[IA√ç]|HIGIENE\\s+Y\\s+SEGURIDAD\\s+OCUPACIONAL|'\n",
        "    r'MULTIMEDIA|PROCESOS\\s+INDUSTRIALES|PRODUCCION\\s+ACUICOLA|'\n",
        "    r'SEGURIDAD\\s+Y\\s+SALUD\\s+PARA\\s+EL\\s+TRABAJO|SOFTWARE|TELECOMUNICACIONES)|'\n",
        "    r'MULTIMEDIA|TOPOGRAFICA)\\b',\n",
        "    r'\\b(SISTEMAS|COMPUTACION|INFORMATICA|TELEMATICA|'\n",
        "    r'TELECOMUNICACIONES|ELECTRONICA|ELECTRICA|INDUSTRIAL|'\n",
        "    r'MECANICA|QUIMICA|AMBIENTAL|CIVIL|BIOMEDICA|SOFTWARE|'\n",
        "    r'GEOLOGICA|METALURGICA|ALIMENTOS|AGRONOMICA|'\n",
        "    r'MINAS|PETROLEOS|AGRICOLA|AGROECOLOGICA|AGROFORESTAL|'\n",
        "    r'AGROINDUSTRIAL|BIOLOGICA|BIOQUIMICA|BIOTECNOLOGICA|'\n",
        "    r'DISENO\\s+DE\\s+PRODUCTO|MATERIALES|SONIDO|TRANSPORTE|'\n",
        "    r'ELECTROMECANICA|MECATRONICA|NANOTECNOLOGIA|TOPOGRAFIA|FORESTAL|'\n",
        "    r'NAVAL|PECUARIA|PESQUERA|SANITARIA|FINANCIERA|'\n",
        "    r'CONTROL|AUTOMATIZACION|INSTRUMENTACION)\\b',\n",
        "    r'\\b(ARQUITECTURA|CONSTRUCCION|CONSTRUCCIONES\\s+CIVILES)\\b',\n",
        "    r'\\bINGENIERA|INGENIERIA\\b',\n",
        "    r'URBANISMO',\n",
        "  ],\n",
        "\n",
        "  'SOCIALES': [\n",
        "    r'\\b(derecho|jurisprudencia|psicolog[ia√≠](?!\\s+(cl[i√≠]nica|ocupacional))|'\n",
        "    r'comunicaci[√≥o]n|periodismo|relaciones\\s+(internacionales|econ[√≥o]micas\\s+internacionales)|'\n",
        "    r'ciencia\\s+pol[i√≠]tica|trabajo\\s+social|antropolog[ia√≠]|sociolog[ia√≠]|'\n",
        "    r'gobierno\\s+y\\s+asuntos\\s+p[√∫u]blicos|planeaci[√≥o]n\\s+y\\s+desarrollo\\s+social|'\n",
        "    r'estudios\\s+(pol[i√≠]ticos|literarios|musicales|sociculturales)|'\n",
        "    r'criminolog[ia√≠]|criminal[√≠i]stica|investigaci[√≥o]n\\s+criminal|'\n",
        "    r'ling[u√º]istica|lenguajes)\\b',\n",
        "    r'\\bANTROPOLOGIA\\b',\n",
        "    r'\\bSOCIOLOGIA\\b',\n",
        "    r'\\bCIENCIAS POLITICAS\\b',\n",
        "    r'\\bCOMUNICACIONES\\b',\n",
        "    r'\\bLINGUISTICA\\b',\n",
        "    r'\\bLENGUAJES Y ESTUDIOS SOCIOCULTURALES\\b',\n",
        "    r'\\bPSICOLOGIA\\b',\n",
        "    r'\\bPROFESIONAL EN PSICOLOGIA\\b',\n",
        "    r'ARQUEOLOGIA',\n",
        "    r'DESARROLLO TERRITORIAL',\n",
        "    r'\\b(GESTION\\s+CULTURAL|GESTION\\s+DEPORTIVA|GESTION\\s+Y\\s+DESARROLLO\\s+URBANOS)\\b',\n",
        "    r'PEDAGOGIA'\n",
        "  ],\n",
        "\n",
        "  'EDUCACION': [\n",
        "    r'\\b(licenciatura|pedagog[ia√≠]|educaci[√≥o]n|docencia|ense√±anza|'\n",
        "    r'did[√°a]ctica|formaci[√≥o]n\\s+docente|desarrollo\\s+familiar)\\b',\n",
        "  ],\n",
        "\n",
        "  'ECONOMIA': [\n",
        "    r'MERCADEO',\n",
        "    r'\\b(?:MERCADEO(?: NACIONAL E INTERNACIONAL| EMPRESARIAL)?|PROFESIONAL EN MERCADEO(?: EMPRESARIAL)?)\\b',\n",
        "    r'\\b(?:MERCADEO|PROFESIONAL\\s+EN\\s+MERCADEO)(?:\\s+(?:NACIONAL\\s+E\\s+INTERNACIONAL|EMPRESARIAL))?\\b',\n",
        "    r'\\b(administraci[√≥o]n|contadur[ia√≠]|econom[ia√≠]|finanzas|mercado[lt]og[√≠i]a|'\n",
        "    r'marketing|negocios|gerencia|log[i√≠]stica|turismo|gesti[√≥o]n\\s+(empresarial|'\n",
        "    r'cultural\\s+y\\s+comunicativa|del\\s+dise[√±n]o|de\\s+la\\s+seguridad|'\n",
        "    r'de\\s+mercados|financiera|urbana|territorial)|comercio\\s+(exterior|internacional)|'\n",
        "    r'administraci[√≥o]n\\s+tur[√≠i]stica\\s+y\\s+hotelera|'\n",
        "    r'contadur[ia√≠]\\s+(publica|internacional)|mercadeo|econom[ia√≠]a)\\b',\n",
        "    r'\\b(?:MERCADEO|MARKETING|PUBLICIDAD)(?:\\s+(?:INTERNACIONAL|NACIONAL|EMPRESARIAL|Y\\s+(?:PUBLICIDAD|MERCADEO|VENTAS|INTERNACIONAL)|E\\s+INTERNACIONAL))?\\b',\n",
        "    r'\\bPROFESIONAL\\s+EN\\s+(?:MERCADEO|MARKETING)(?:\\s+(?:EMPRESARIAL|Y\\s+PUBLICIDAD))?\\b',\n",
        "    r'\\b(?:ADMINISTRACI[√ìO]N|CONTADUR[√çI]A|ECONOM[√çI]A|FINANZAS|'\n",
        "    r'GERENCIA|LOG[√çI]STICA|TURISMO|NEGOCIOS|COMERCIO)\\b',\n",
        "  ],\n",
        "\n",
        "  'CIENCIAS': [\n",
        "    r'\\b(matem[√°a]tica|f[√≠i]sica|qu[√≠i]mica|biolog[ia√≠]|geolog[ia√≠]|'\n",
        "    r'estad[i√≠]stica|ciencias\\s+b[√°a]sicas|ecolog[ia√≠]|'\n",
        "    r'ciencias\\s+(ambientales|biol[√≥o]gicas|del\\s+mar|n[√°a]uticas|'\n",
        "    r'militares\\s+(aeron[√°a]uticas|navales)?)|geograf[ia√≠]|'\n",
        "    r'astrof[√≠i]sica|geociencias|bioingenier[ia√≠]a|'\n",
        "    r'biotecnolog[ia√≠]a|bioquimica|deporte|recreaci[√≥o]n|'\n",
        "    r'entrenamiento\\s+deportivo)\\b',\n",
        "    r'\\bBIOLOGIA\\b',\n",
        "    r'\\bECOLOGIA\\b',\n",
        "    r'\\bMATEMATICAS\\b',\n",
        "    r'\\bGEOGRAFIA\\b',\n",
        "    r'\\bGEOLOGIA\\b',\n",
        "    r'\\bDEPORTE\\b',\n",
        "    r'\\bRECREACION\\b',\n",
        "    r'\\bENTRENAMIENTO DEPORTIVO\\b',\n",
        "    r'\\bPROFESIONAL EN DEPORTE\\b',\n",
        "    r'\\bPROFESIONAL EN ENTRENAMIENTO DEPORTIVO\\b',\n",
        "    r'\\bCIENCIAS DEL DEPORTE\\b',\n",
        "    r'\\bCIENCIAS DEL DEPORTE Y LA RECREACION\\b',\n",
        "    r'\\bCIENCIAS MILITARES\\b',\n",
        "    r'\\bCIENCIAS NAVALES PARA OFICIALES DE INFANTERIA DE MARINA\\b',\n",
        "    r'\\bCIENCIAS NAVALES PARA OFICIALES NAVALES\\b',\n",
        "    r'ASTRONOMIA',\n",
        "    r'OCEANOGRAFIA'\n",
        "  ],\n",
        "\n",
        "  'ARTES_HUMANIDADES': [\n",
        "    r'\\b(filosof[ia√≠]|historia|literatura|lenguas|traducci[√≥o]n|'\n",
        "    r'arte|danza|dram[√°a]tico|cine|audiovisuales|televisi[√≥o]n|'\n",
        "    r'radio|producci[√≥o]n\\s+(cinematogr[√°a]fica|audiovisual|musical)|'\n",
        "    r'dise[√±n]o\\s+(gr[√°a]fico|industrial|interior|de\\s+modas|'\n",
        "    r'de\\s+espacios|digital|interactivo|visual|multimedia|'\n",
        "    r'de\\s+vestuario|escenogr[√°a]fico)|gastronom[ia√≠]a|'\n",
        "    r'culinaria|teolog[ia√≠]|musicolog[ia√≠]|interpretaci[√≥o]n\\s+musical|'\n",
        "    r'fotograf[ia√≠]a|bibliotecolog[ia√≠]a|archiv[√≠i]stica|'\n",
        "    r'creaci[√≥o]n\\s+literaria|espanol|filologia|'\n",
        "    r'musica|formaci[√≥o]n\\s+musical|estudios\\s+(literarios|musicales|culturales))\\b',\n",
        "    r'\\bARTES\\b',\n",
        "    r'\\bMUSICA\\b',\n",
        "    r'\\bFILOSOFIA\\b',\n",
        "    r'\\bFILOSOFIA Y HUMANIDADES\\b',\n",
        "    r'\\bFILOSOFIA Y LETRAS\\b',\n",
        "    r'\\bESPANOL Y FILOLOGIA CLASICA\\b',\n",
        "    r'\\bFILOLOGIA E IDIOMAS\\b',\n",
        "    r'\\bFILOLOGIA HISPANICA\\b',\n",
        "    r'\\bCIENCIAS BIBLICAS\\b',\n",
        "    r'\\bTEOLOGIA\\b',\n",
        "    r'\\bDISENO\\b',\n",
        "    r'\\bDISENO DE MEDIOS INTERACTIVOS\\b',\n",
        "    r'\\bDISENO Y GESTION DE LA MODA\\b',\n",
        "    r'\\bDISENO Y PRODUCCION DE MODA\\b',\n",
        "    r'\\bCREACION LITERARIA\\b',\n",
        "    r'\\bESTUDIOS Y GESTION CULTURAL\\b',\n",
        "    r'\\bCIENCIAS\\s+DE\\s+LA\\s+INFORMACION\\s+Y\\s+LA\\s+DOCUMENTACION\\b',\n",
        "    r'ANIMACION',\n",
        "    r'TEATRO',\n",
        "    r'DIRECCION DE BANDA',\n",
        "    r'CONSERVACION Y RESTAURACION DE BIENES MUEBLES',\n",
        "    r'CROSSMEDIA',\n",
        "    r'NARRATIVAS DIGITALES',\n",
        "  ],\n",
        "\n",
        "  'AGROPECUARIO': [\n",
        "    r'\\b(agronom[ia√≠]|agroecolog[ia√≠]a|agroforestal|agroindustrial|'\n",
        "    r'agropecuaria|zootecnia|acuicultura|pesquera|'\n",
        "    r'producci[√≥o]n\\s+agroindustrial|agronegocios|'\n",
        "    r'profesional\\s+en\\s+(agroindustria|agronegocios))\\b',\n",
        "    r'\\bAGRONOMIA\\b',\n",
        "    r'\\bAGRONOMIA DEL TROPICO HUMEDO\\b',\n",
        "  ]\n",
        "}\n",
        "\n",
        "\n",
        "# Funci√≥n para mapear programa a √°rea\n",
        "def mapper_prgm_academico_to_snies(programa):\n",
        "  if not isinstance(programa, str):\n",
        "      return 'OTRO'\n",
        "\n",
        "  # Correcci√≥n de errores tipogr√°ficos frecuentes\n",
        "  p = programa.upper().strip()\n",
        "  p = re.sub(r'[^\\w\\s]', ' ', p)  # Elimina puntuaci√≥n\n",
        "  p = re.sub(r'\\s+', ' ', p)      # Elimina espacios m√∫ltiples\n",
        "\n",
        "  # Corecci√≥n de errores de digitaci√≥n del dataset\n",
        "  p = re.sub(r'\\bADMINSITRACION\\b', 'ADMINISTRACION', p)\n",
        "  p = re.sub(r'\\bINTRUMENTACION\\b', 'INSTRUMENTACION', p)\n",
        "  p = re.sub(r'\\bCOMUNICACIN\\b', 'COMUNICACION', p)\n",
        "  p = re.sub(r'\\bMERCADEO\\b', 'MERCADOTECNIA', p)\n",
        "  p = re.sub(r'\\bCOMUNICACIN\\b', 'COMUNICACION', p)\n",
        "  p = re.sub(r'\\bPSICOLOGIA\\b', 'PSICOLOGIA', p)\n",
        "\n",
        "  # Busca en cada √°rea\n",
        "  for area, patrones in snies_areas.items():\n",
        "      for patron in patrones:\n",
        "          if re.search(patron, p, re.IGNORECASE):\n",
        "              return area\n",
        "  return 'OTRO'"
      ],
      "metadata": {
        "id": "Co5w2hKGk4fr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_prgm_departamento_to_region(data):\n",
        "  region_map = {\n",
        "    # Caribe\n",
        "    'ATLANTICO': 'CARIBE', 'BOLIVAR': 'CARIBE', 'SUCRE': 'CARIBE', 'MAGDALENA': 'CARIBE',\n",
        "    'LA GUAJIRA': 'CARIBE', 'CESAR': 'CARIBE', 'SAN ANDRES': 'CARIBE',\n",
        "\n",
        "    # Andina\n",
        "    'BOGOT√Å': 'ANDINA', 'ANTIOQUIA': 'ANDINA', 'HUILA': 'ANDINA', 'CUNDINAMARCA': 'ANDINA',\n",
        "    'TOLIMA': 'ANDINA', 'VALLE': 'ANDINA', 'QUINDIO': 'ANDINA', 'RISARALDA': 'ANDINA',\n",
        "    'CORDOBA': 'ANDINA', 'BOYACA': 'ANDINA', 'NARI√ëO': 'ANDINA', 'CALDAS': 'ANDINA',\n",
        "    'SANTANDER': 'ANDINA', 'NORTE SANTANDER': 'ANDINA',\n",
        "\n",
        "    # Pac√≠fica\n",
        "    'CAUCA': 'PACIFICA', 'CHOCO': 'PACIFICA', 'NARI√ëO': 'PACIFICA',\n",
        "\n",
        "    # Orinoqu√≠a\n",
        "    'META': 'ORINOQUIA', 'CASANARE': 'ORINOQUIA', 'ARAUCA': 'ORINOQUIA', 'GUAVIARE': 'ORINOQUIA',\n",
        "\n",
        "    # Amaz√≥nica\n",
        "    'AMAZONAS': 'AMAZONICA', 'CAQUETA': 'AMAZONICA', 'PUTUMAYO': 'AMAZONICA',\n",
        "    'VAUPES': 'AMAZONICA'\n",
        "  }\n",
        "\n",
        "  data['E_PRGM_DEPARTAMENTO'] = data['E_PRGM_DEPARTAMENTO'].map(region_map).fillna('OTRO')\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "w1h4yZr5mbLF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_nulos_2(data):\n",
        "  imputer = SimpleImputer(strategy='most_frequent')\n",
        "  data['F_ESTRATOVIVIENDA'] = imputer.fit_transform(data[['F_ESTRATOVIVIENDA']])[:, 0]\n",
        "  data['F_TIENEINTERNET'] = imputer.fit_transform(data[['F_TIENEINTERNET']])[:, 0]\n",
        "  data['F_TIENECOMPUTADOR'] = imputer.fit_transform(data[['F_TIENECOMPUTADOR']])[:, 0]\n",
        "  data['F_TIENELAVADORA'] = imputer.fit_transform(data[['F_TIENELAVADORA']])[:, 0]\n",
        "  data['F_TIENEAUTOMOVIL'] = imputer.fit_transform(data[['F_TIENEAUTOMOVIL']])[:, 0]\n",
        "\n",
        "  data['E_VALORMATRICULAUNIVERSIDAD'] = imputer.fit_transform(data[['E_VALORMATRICULAUNIVERSIDAD']])[:, 0]\n",
        "  data['E_PAGOMATRICULAPROPIO'] = imputer.fit_transform(data[['E_PAGOMATRICULAPROPIO']])[:, 0]\n",
        "\n",
        "  data['F_EDUCACIONPADRE'] = data.groupby('F_ESTRATOVIVIENDA')['F_EDUCACIONPADRE'].transform(lambda x: x.fillna(x.mode()[0]))\n",
        "  data['F_EDUCACIONMADRE'] = data.groupby('F_ESTRATOVIVIENDA')['F_EDUCACIONMADRE'].transform(lambda x: x.fillna(x.mode()[0]))\n",
        "\n",
        "  data['E_HORASSEMANATRABAJA'] = data['E_HORASSEMANATRABAJA'].map({'0': 0, 'Menos de 10 horas': 9, 'Entre 11 y 20 horas': 15.5, 'Entre 21 y 30 horas': 25.5, 'M√°s de 30 horas': 31})\n",
        "  data['E_HORASSEMANATRABAJA'] = data['E_HORASSEMANATRABAJA'].fillna((data['E_HORASSEMANATRABAJA'].mean()).round(3))\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "BqVCTeXqmbCh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_to_numeric(data):\n",
        "  data = pd.get_dummies(data, columns=['E_VALORMATRICULAUNIVERSIDAD'], dtype=np.uint8)\n",
        "  data.drop(columns=['E_VALORMATRICULAUNIVERSIDAD_No pag√≥ matr√≠cula'], inplace=True)\n",
        "\n",
        "  data = pd.get_dummies(data, columns=['F_ESTRATOVIVIENDA'], dtype=np.uint8)\n",
        "  data.drop(columns=['F_ESTRATOVIVIENDA_Sin Estrato'], inplace=True)\n",
        "  data.columns = data.columns.str.replace('_Estrato ', '_')\n",
        "\n",
        "  data['F_TIENEINTERNET'] = data['F_TIENEINTERNET'].map({'Si': 1, 'No': 0}).astype(np.int8)\n",
        "  data['F_TIENELAVADORA'] = data['F_TIENELAVADORA'].map({'Si': 1, 'No': 0}).astype(np.int8)\n",
        "  data['F_TIENEAUTOMOVIL'] = data['F_TIENEAUTOMOVIL'].map({'Si': 1, 'No': 0}).astype(np.int8)\n",
        "  data['E_PAGOMATRICULAPROPIO'] = data['E_PAGOMATRICULAPROPIO'].map({'Si': 1, 'No': 0}).astype(np.int8)\n",
        "  data['F_TIENECOMPUTADOR'] = data['F_TIENECOMPUTADOR'].map({'Si': 1, 'No': 0}).astype(np.int8)\n",
        "\n",
        "  mapping = {\n",
        "    'Ninguno': 0,\n",
        "    'No sabe': 0,\n",
        "    'No Aplica': 0,\n",
        "    'Primaria incompleta': 1,\n",
        "    'Primaria completa': 2,\n",
        "    'Secundaria (Bachillerato) incompleta': 3,\n",
        "    'Secundaria (Bachillerato) completa': 5,\n",
        "    'T√©cnica o tecnol√≥gica incompleta': 7,\n",
        "    'T√©cnica o tecnol√≥gica completa': 10,\n",
        "    'Educaci√≥n profesional incompleta': 13,\n",
        "    'Educaci√≥n profesional completa': 20,\n",
        "    'Postgrado': 40\n",
        "  }\n",
        "\n",
        "  data['F_EDUCACIONMADRE'] = data['F_EDUCACIONMADRE'].map(mapping).astype(np.uint8)\n",
        "  data['F_EDUCACIONPADRE'] = data['F_EDUCACIONPADRE'].map(mapping).astype(np.uint8)\n",
        "\n",
        "  data = pd.get_dummies(data, columns=['E_PRGM_DEPARTAMENTO'], prefix='REGION', dtype=np.uint8)\n",
        "\n",
        "  data = pd.get_dummies(data, columns=['AREA_SNIES'], dtype=np.uint8)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "m34cxX5UukxB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_data(data):\n",
        "  data['E_HORASSEMANATRABAJA'] = (data['E_HORASSEMANATRABAJA'] - data['E_HORASSEMANATRABAJA'].min()) / (data['E_HORASSEMANATRABAJA'].max() - data['E_HORASSEMANATRABAJA'].min())\n",
        "  data['F_EDUCACIONMADRE'] = (data['F_EDUCACIONMADRE'] - data['F_EDUCACIONMADRE'].min()) / (data['F_EDUCACIONMADRE'].max() - data['F_EDUCACIONMADRE'].min())\n",
        "  data['F_EDUCACIONPADRE'] = (data['F_EDUCACIONPADRE'] - data['F_EDUCACIONPADRE'].min()) / (data['F_EDUCACIONPADRE'].max() - data['F_EDUCACIONPADRE'].min())\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "YWs4SRGD5mpm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el dataset, las columnas nombradas como `INDICADOR_1`, `INDICADOR_2`, `INDICADOR_3` e `INDICADOR_4`, no queda muy claro que representan, que informaci√≥n brindan. Se procede a elimar estos datos para comprobar si aportan al modelo o son contraproducentes.\n",
        "\n",
        "Despues de evaluar el modelo con estos datos, se realiza una segunda evaluacci√≥n del modelo, esta vez sin estas columnas presentes, esperando observar un cambio en el Test Accuracy. De esta forma, tomar la decisi√≥n de conservarlas o eliminarlas."
      ],
      "metadata": {
        "id": "Yoxfh7YJKFLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_indicadors(data):\n",
        "  data.drop(['INDICADOR_1', 'INDICADOR_2', 'INDICADOR_3', 'INDICADOR_4'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "d5PuOugvIO_d"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea una columna, para intentar mejorar el valor predictivo del modelo.\n",
        "\n",
        "Se parte de la premisa de que el esfuerzo de un estudiante al pagar su matricula, cambia si es estrato 1 o estrato 6."
      ],
      "metadata": {
        "id": "H6cXcyp4982a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def new_column_ESFUERZO_RELATIVO(data):\n",
        "  PAGOMATRICULAPROPIO = data['E_PAGOMATRICULAPROPIO'].map({\n",
        "    'Si': 1,\n",
        "    'No': 0\n",
        "  }).astype(np.int8)\n",
        "\n",
        "  estrato_map = {\n",
        "      'Estrato 1': 1,\n",
        "      'Estrato 2': 2,\n",
        "      'Estrato 3': 3,\n",
        "      'Estrato 4': 4,\n",
        "      'Estrato 5': 5,\n",
        "      'Estrato 6': 6,\n",
        "      'Sin Estrato': 3.5\n",
        "  }\n",
        "\n",
        "  ESTRATOVIVIENDA = data['F_ESTRATOVIVIENDA'].map(estrato_map).astype(np.int8)\n",
        "\n",
        "  data['ESFUERZO_RELATIVO'] = PAGOMATRICULAPROPIO / ESTRATOVIVIENDA + 1e-6"
      ],
      "metadata": {
        "id": "fVzP5_VE89Po"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_saber_pro_5(data):\n",
        "  data = clean_data_base_2(data)\n",
        "  data = clean_nulos_2(data)\n",
        "  delete_indicadors(data)\n",
        "  new_column_ESFUERZO_RELATIVO(data)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "gD07Zk-B7vC5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main"
      ],
      "metadata": {
        "id": "clbLIOXhDnGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpieza de los datos"
      ],
      "metadata": {
        "id": "D3Pufy1NrGv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = train.copy()\n",
        "df = clean_saber_pro_5(df)"
      ],
      "metadata": {
        "id": "EwL_CbpfkctI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxmmthHPFPZv",
        "outputId": "1696de74-e981-44fa-8a59-185a70db2dc0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 692500 entries, 0 to 692499\n",
            "Data columns (total 14 columns):\n",
            " #   Column                       Non-Null Count   Dtype  \n",
            "---  ------                       --------------   -----  \n",
            " 0   E_PRGM_ACADEMICO             692500 non-null  object \n",
            " 1   E_PRGM_DEPARTAMENTO          692500 non-null  object \n",
            " 2   E_VALORMATRICULAUNIVERSIDAD  692500 non-null  object \n",
            " 3   E_HORASSEMANATRABAJA         692500 non-null  float64\n",
            " 4   F_ESTRATOVIVIENDA            692500 non-null  object \n",
            " 5   F_TIENEINTERNET              692500 non-null  object \n",
            " 6   F_EDUCACIONPADRE             692500 non-null  object \n",
            " 7   F_TIENELAVADORA              692500 non-null  object \n",
            " 8   F_TIENEAUTOMOVIL             692500 non-null  object \n",
            " 9   E_PAGOMATRICULAPROPIO        692500 non-null  object \n",
            " 10  F_TIENECOMPUTADOR            692500 non-null  object \n",
            " 11  F_EDUCACIONMADRE             692500 non-null  object \n",
            " 12  RENDIMIENTO_GLOBAL           692500 non-null  object \n",
            " 13  ESFUERZO_RELATIVO            692500 non-null  float64\n",
            "dtypes: float64(2), object(12)\n",
            "memory usage: 74.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pasa la variable a predecir, de categorica a num√©rica"
      ],
      "metadata": {
        "id": "b-UUNhgiEuqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {\n",
        "    'alto': 4,\n",
        "    'medio-alto': 3,\n",
        "    'medio-bajo': 2,\n",
        "    'bajo': 1\n",
        "}\n",
        "\n",
        "df['RENDIMIENTO_GLOBAL'] = df['RENDIMIENTO_GLOBAL'].map(mapping).astype('int8')"
      ],
      "metadata": {
        "id": "yVMeFZXYEyYn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "Mph8UMTFRS9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LightGBM** (Light Gradient Boosting Machine) es una biblioteca de **aprendizaje autom√°tico** optimizada para tareas de clasificaci√≥n y regresi√≥n. Se basa en el algoritmo de **Gradient Boosting Decision Trees** (GBDT), pero con mejoras clave que lo hacen m√°s r√°pido y eficiente, especialmente en grandes vol√∫menes de datos. LightGBM utiliza t√©cnicas como **histogramas** para acelerar la construcci√≥n de √°rboles, soporte nativo para variables categ√≥ricas, y optimizaci√≥n en la paralelizaci√≥n del entrenamiento. Esto lo convierte en una opci√≥n popular para problemas de **gran escala** y **alto rendimiento**."
      ],
      "metadata": {
        "id": "3z7Y059AvBqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "sJp-1v0BCU7P"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separa del dataset la variable a predecir"
      ],
      "metadata": {
        "id": "J9zmDprcCNae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['RENDIMIENTO_GLOBAL'])\n",
        "y = df.RENDIMIENTO_GLOBAL"
      ],
      "metadata": {
        "id": "_1983kLoRTot"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convierte las columnas a categor√≠a, para aprovechar las optimizaciones de LightGBM"
      ],
      "metadata": {
        "id": "kZ0gi5VEHrn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in X.columns:\n",
        "    X[col] = X[col].astype('category')"
      ],
      "metadata": {
        "id": "f4VadyZ4Hb3G"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUNIMDvcOeWy",
        "outputId": "32763607-4782-46e7-e9ca-6a09571b2b4c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 692500 entries, 0 to 692499\n",
            "Data columns (total 13 columns):\n",
            " #   Column                       Non-Null Count   Dtype   \n",
            "---  ------                       --------------   -----   \n",
            " 0   E_PRGM_ACADEMICO             692500 non-null  category\n",
            " 1   E_PRGM_DEPARTAMENTO          692500 non-null  category\n",
            " 2   E_VALORMATRICULAUNIVERSIDAD  692500 non-null  category\n",
            " 3   E_HORASSEMANATRABAJA         692500 non-null  category\n",
            " 4   F_ESTRATOVIVIENDA            692500 non-null  category\n",
            " 5   F_TIENEINTERNET              692500 non-null  category\n",
            " 6   F_EDUCACIONPADRE             692500 non-null  category\n",
            " 7   F_TIENELAVADORA              692500 non-null  category\n",
            " 8   F_TIENEAUTOMOVIL             692500 non-null  category\n",
            " 9   E_PAGOMATRICULAPROPIO        692500 non-null  category\n",
            " 10  F_TIENECOMPUTADOR            692500 non-null  category\n",
            " 11  F_EDUCACIONMADRE             692500 non-null  category\n",
            " 12  ESFUERZO_RELATIVO            692500 non-null  category\n",
            "dtypes: category(13)\n",
            "memory usage: 9.3 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separa una parte de los datos para testear el modelo"
      ],
      "metadata": {
        "id": "KoOtqVMQsk1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y - 1,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train: {X_train.shape} | Test: {X_test.shape}\")\n",
        "print(f\"Distribuci√≥n train: {np.bincount(y_train)/len(y_train)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjDx1d8mI2Qf",
        "outputId": "1c2397f4-be6c-49cb-e5c6-c6dcf43480bf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (554000, 13) | Test: (138500, 13)\n",
            "Distribuci√≥n train: [0.24980144 0.24877256 0.24782491 0.25360108]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se configuran los par√°metros del modelo para mejorar el rendimiento y evitar el sobreajuste.\n",
        "\n",
        "- `objective`: `multiclass`: Indica que se est√° realizando una clasificaci√≥n multiclase (es decir, m√°s de dos clases). El modelo ajustar√° su objetivo para esto.\n",
        "\n",
        "- `num_class`: `4`: Especifica que hay 4 clases en el problema de clasificaci√≥n.\n",
        "\n",
        "- `metric`: `multi_logloss`: M√©trica utilizada para la evaluaci√≥n del modelo. En este caso, se utiliza log loss para la clasificaci√≥n multiclase. Un valor m√°s bajo indica un mejor modelo.\n",
        "\n",
        "- `boosting_type`: `gbdt`: El tipo de boosting utilizado es Gradient Boosting Decision Tree (GBDT), que es el enfoque por defecto en LightGBM.\n",
        "\n",
        "- `num_leaves`: `95`: Especifica el n√∫mero m√°ximo de hojas por √°rbol. Un valor mayor implica √°rboles m√°s complejos, con mayor capacidad para aprender patrones complejos, pero tambi√©n puede aumentar el riesgo de sobreajuste (overfitting).\n",
        "\n",
        "- `min_data_in_leaf`: `180`: El n√∫mero m√≠nimo de muestras que debe contener una hoja del √°rbol. Este par√°metro ayuda a controlar el sobreajuste, al evitar que se creen hojas con muy pocos ejemplos.\n",
        "\n",
        "- `min_sum_hessian_in_leaf`: `20`: Es un par√°metro que mejora la estabilidad del modelo, especialmente en problemas con clases desbalanceadas. Controla el n√∫mero m√≠nimo de \"hessianos\" (una medida de curvatura) necesarios en una hoja.\n",
        "\n",
        "- `cat_l2`: `15.0` y `cat_smooth`: `20.0`: Son par√°metros de regularizaci√≥n espec√≠ficos para las variables categ√≥ricas. Ayudan a evitar que el modelo se sobreajuste a categor√≠as que tienen pocos ejemplos.\n",
        "\n",
        "- `feature_fraction`: `0.75`: La fracci√≥n de caracter√≠sticas a considerar en cada iteraci√≥n del entrenamiento. Un valor de 0.75 significa que LightGBM utilizar√° el 75% de las caracter√≠sticas disponibles en cada iteraci√≥n para construir los √°rboles. Esto puede mejorar la generalizaci√≥n y reducir el sobreajuste.\n",
        "\n",
        "- `bagging_fraction`: `0.8` y `bagging_freq`: `3`: Estas son t√©cnicas de bagging (muestreo aleatorio de los datos):\n",
        "\n",
        "- `bagging_fraction`: Especifica la fracci√≥n de los datos que se utilizan en cada iteraci√≥n (en este caso el 80% de los datos).\n",
        "\n",
        "- `bagging_freq`: Controla la frecuencia con la que se aplica el bagging. Con un valor de 3, LightGBM aplicar√° bagging cada 3 iteraciones.\n",
        "\n",
        "- `learning_rate`: `0.012`: Tasa de aprendizaje. Un valor m√°s bajo hace que el modelo aprenda m√°s lentamente, lo cual generalmente mejora la estabilidad del modelo, pero requiere m√°s boosting rounds (iteraciones).\n",
        "\n",
        "- `lambda_l1`: `1.0` y `lambda_l2`: `1.5`: Son par√°metros de regularizaci√≥n L1 y L2. Ayudan a evitar el sobreajuste penalizando grandes coeficientes en las caracter√≠sticas.\n",
        "\n",
        "- `max_depth`: `10`: Indica que ning√∫n √°rbol tendr√° m√°s de 10 niveles de profundidad.\n",
        "\n",
        "- `verbosity`: `-1`: Controla el nivel de salida de los registros del modelo. `-1` suprime la salida, lo que significa que no ver√°s detalles del proceso de entrenamiento.\n",
        "\n",
        "- `random_state`: `42`: Fija la semilla aleatoria para asegurar la reproducibilidad de los resultados.\n",
        "\n",
        "- `is_unbalance`: `True`: Activa el ajuste autom√°tico de pesos por clase para mejorar el desempe√±o en clases dif√≠ciles de predecir.\n"
      ],
      "metadata": {
        "id": "sRb3vYtN5TCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "  'objective': 'multiclass',\n",
        "  'num_class': 4,\n",
        "  'metric': 'multi_logloss',\n",
        "  'boosting_type': 'gbdt',\n",
        "  'num_leaves': 95,\n",
        "  'min_data_in_leaf': 180,\n",
        "  'min_sum_hessian_in_leaf': 20,\n",
        "  'cat_l2': 15.0,\n",
        "  'cat_smooth': 20.0,\n",
        "  'feature_fraction': 0.75,\n",
        "  'bagging_fraction': 0.8,\n",
        "  'bagging_freq': 3,\n",
        "  'learning_rate': 0.012,\n",
        "  'lambda_l1': 1.0,\n",
        "  'lambda_l2': 1.5,\n",
        "  'max_depth': 10,\n",
        "  'verbosity': -1,\n",
        "  'random_state': 42,\n",
        "  'is_unbalance': True,\n",
        "}"
      ],
      "metadata": {
        "id": "vm9MbzT3B-_7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crean los conjuntos de datos para entrenamiento y validaci√≥n, especificando las caracter√≠sticas categ√≥ricas."
      ],
      "metadata": {
        "id": "cf5rqgs8CDvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = lgb.Dataset(X_train, y_train, categorical_feature=X_train.columns.tolist())\n",
        "val_data = lgb.Dataset(X_test, y_test, reference=train_data)"
      ],
      "metadata": {
        "id": "KTPUcuczD8aG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se entrena el modelo con un n√∫mero m√°ximo de 2000 iteraciones, aplicando `early stopping` para detener el entrenamiento si no hay mejora durante 100 iteraciones consecutivas. Esto asegura que el modelo se entrene de manera eficiente y no se sobreajuste a los datos de entrenamiento.\n",
        "\n",
        "El c√≥digo tambi√©n registra el progreso del entrenamiento cada 200 iteraciones para monitorear el desempe√±o del modelo."
      ],
      "metadata": {
        "id": "t9EaixFRD9SY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = lgb.train(\n",
        "  params, train_data,\n",
        "  valid_sets=[val_data],\n",
        "  num_boost_round=2000,\n",
        "  callbacks=[\n",
        "    lgb.early_stopping(100),\n",
        "    lgb.log_evaluation(200)\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-M2hS1JDRi6",
        "outputId": "d2f28023-35ab-4f5c-9949-37ef5e872eb3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[200]\tvalid_0's multi_logloss: 1.2123\n",
            "[400]\tvalid_0's multi_logloss: 1.20073\n",
            "[600]\tvalid_0's multi_logloss: 1.19799\n",
            "[800]\tvalid_0's multi_logloss: 1.19671\n",
            "[1000]\tvalid_0's multi_logloss: 1.19606\n",
            "[1200]\tvalid_0's multi_logloss: 1.19565\n",
            "[1400]\tvalid_0's multi_logloss: 1.19559\n",
            "Early stopping, best iteration is:\n",
            "[1301]\tvalid_0's multi_logloss: 1.19557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evalua el rendimiento del modelo"
      ],
      "metadata": {
        "id": "-Pt1H-FbDGEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test).argmax(axis=1) + 1\n",
        "train_acc = accuracy_score(y_train + 1, model.predict(X_train).argmax(axis=1) + 1)\n",
        "test_acc = accuracy_score(y_test + 1, y_pred)\n",
        "\n",
        "print(\"\\nüìä Resultados LightGBM:\")\n",
        "print(f\"   Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"   Test Accuracy:  {test_acc:.4f}\")\n",
        "print(f\"   Overfitting:    {train_acc - test_acc:.4f} (ideal < 0.05)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7LRCUnwEMsZ",
        "outputId": "88fbfcb1-05ef-4733-9310-279ee3419a25"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Resultados LightGBM:\n",
            "   Train Accuracy: 0.4781\n",
            "   Test Accuracy:  0.4355\n",
            "   Overfitting:    0.0426 (ideal < 0.05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resultados de Rendimiento, con diferentes preprocesamientos."
      ],
      "metadata": {
        "id": "FT68GflJP7ap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo\n",
        "\n",
        "```python\n",
        "params = {\n",
        "  'objective': 'multiclass',\n",
        "  'num_class': 4,\n",
        "  'metric': 'multi_logloss',\n",
        "  'boosting_type': 'gbdt',\n",
        "  'num_leaves': 127,          \n",
        "  'min_data_in_leaf': 150,    \n",
        "  'min_sum_hessian_in_leaf': 10,\n",
        "  'cat_l2': 5.0,              \n",
        "  'cat_smooth': 10.0,\n",
        "  'feature_fraction': 0.85,\n",
        "  'bagging_fraction': 0.9,\n",
        "  'bagging_freq': 2,\n",
        "  'learning_rate': 0.02,      \n",
        "  'lambda_l1': 0.5,\n",
        "  'lambda_l2': 0.5,\n",
        "  'max_depth': -1,           \n",
        "  'verbosity': -1,\n",
        "  'random_state': 42\n",
        "}\n",
        "\n",
        "train_data = lgb.Dataset(X_train, y_train, categorical_feature=X_train.columns.tolist())\n",
        "val_data = lgb.Dataset(X_test, y_test, reference=train_data)\n",
        "\n",
        "model = lgb.train(\n",
        "  params, train_data,\n",
        "  valid_sets=[val_data],\n",
        "  num_boost_round=2000,\n",
        "  callbacks=[\n",
        "    lgb.early_stopping(100),\n",
        "    lgb.log_evaluation(200)\n",
        "  ]\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "p7CtZkbedpGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se usan diferentes estrategias de preprocesado de los datos y se evalua, con la intencci√≥n de encontrar la que mejor resultados brinde."
      ],
      "metadata": {
        "id": "WDxNzxRIFp5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rendimiento del modelo con:\n",
        "```python\n",
        "  def clean_saber_pro_4(data):\n",
        "    data = clean_data_base_2(data)\n",
        "    data = clean_nulos_2(data)\n",
        "\n",
        "    return data\n",
        "```\n",
        "    üìä Resultados LightGBM:\n",
        "    Train Accuracy: 0.6218\n",
        "    Test Accuracy:  0.4245\n",
        "    Overfitting:    0.1972 (ideal < 0.05)\n",
        "\n",
        "`Overfitting` muy alto\n",
        "\n",
        "---\n",
        "\n",
        "Rendimiento del modelo con:\n",
        "```python\n",
        "  def clean_saber_pro_4(data):\n",
        "    data = clean_data_base_2(data)\n",
        "    data['AREA_SNIES'] = data['E_PRGM_ACADEMICO'].apply(mapper_prgm_academico_to_snies)\n",
        "    data.drop('E_PRGM_ACADEMICO', axis=1, inplace=True)\n",
        "    data = clean_nulos_2(data)\n",
        "\n",
        "    return data\n",
        "```\n",
        "    üìä Resultados LightGBM:\n",
        "    Train Accuracy: 0.5896\n",
        "    Test Accuracy:  0.4061\n",
        "    Overfitting:    0.1836 (ideal < 0.05)\n",
        "\n",
        "`Overfitting` muy alto\n",
        "\n",
        "---\n",
        "\n",
        "Rendimiento del modelo con:\n",
        "```python\n",
        "def clean_saber_pro_4(data):\n",
        "  data = clean_data_base_2(data)\n",
        "  data['AREA_SNIES'] = data['E_PRGM_ACADEMICO'].apply(mapper_prgm_academico_to_snies)\n",
        "  data.drop('E_PRGM_ACADEMICO', axis=1, inplace=True)\n",
        "  data = clean_nulos_2(data)\n",
        "  delete_indicadors(data)\n",
        "\n",
        "  return data\n",
        "```\n",
        "\n",
        "    üìä Resultados LightGBM:\n",
        "    Train Accuracy: 0.4592\n",
        "    Test Accuracy:  0.4194\n",
        "    Overfitting:    0.0398 (ideal < 0.05)\n",
        "\n",
        "`Overfitting` es aceptable\n",
        "\n",
        "---\n",
        "\n",
        "Rendimiento del modelo con:\n",
        "```python\n",
        "  def clean_saber_pro_4(data):\n",
        "    data = clean_data_base_2(data)\n",
        "    data = clean_nulos_2(data)\n",
        "    delete_indicadors(data)\n",
        "\n",
        "    return data\n",
        "```\n",
        "    üìä Resultados LightGBM:\n",
        "    Train Accuracy: 0.4915\n",
        "    Test Accuracy:  0.4358\n",
        "    Overfitting:    0.0557 (ideal < 0.05)\n",
        "\n",
        "---\n",
        "Rendimiento del modelo con:\n",
        "```python\n",
        "  def clean_saber_pro_4(data):\n",
        "    data = clean_data_base_2(data)\n",
        "    data['AREA_SNIES'] = data['E_PRGM_ACADEMICO'].apply(mapper_prgm_academico_to_snies)\n",
        "    data.drop('E_PRGM_ACADEMICO', axis=1, inplace=True)\n",
        "    data = clean_prgm_departamento_to_region(data)\n",
        "    data = clean_nulos_2(data)\n",
        "    delete_indicadors(data)\n",
        "\n",
        "    return data\n",
        "```\n",
        "\n",
        "    üìä Resultados LightGBM:\n",
        "    Train Accuracy: 0.4332\n",
        "    Test Accuracy:  0.4082\n",
        "    Overfitting:    0.0250 (ideal < 0.05)\n",
        "\n",
        "`Overfitting` mejora, pero el rendimiento en test en considerablemente menor que con otras estrategias."
      ],
      "metadata": {
        "id": "e4tFuFpTNn6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se ajustan los parametros:\n",
        "```python\n",
        "  params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': 4,\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 95,\n",
        "    'min_data_in_leaf': 180,\n",
        "    'min_sum_hessian_in_leaf': 20,\n",
        "    'cat_l2': 15.0,\n",
        "    'cat_smooth': 20.0,\n",
        "    'feature_fraction': 0.75,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 3,\n",
        "    'learning_rate': 0.015,\n",
        "    'lambda_l1': 1.0,\n",
        "    'lambda_l2': 1.5,\n",
        "    'max_depth': 10,\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42,\n",
        "\n",
        "    'is_unbalance': True,\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "Rendimiento del modelo con:\n",
        "```python\n",
        "  def clean_saber_pro_4(data):\n",
        "    data = clean_data_base_2(data)\n",
        "    data = clean_nulos_2(data)\n",
        "    delete_indicadors(data)\n",
        "\n",
        "    return data\n",
        "```\n",
        "\n",
        "    üìä Resultados LightGBM:\n",
        "    Train Accuracy: 0.4827\n",
        "    Test Accuracy:  0.4354\n",
        "    Overfitting:    0.0473 (ideal < 0.05)\n",
        "\n",
        "\n",
        "Se ajusta el parametro `learning_rate` del modelo\n",
        "\n",
        "    'learning_rate': 0.012,\n",
        "\n",
        "---\n",
        "\n",
        "    üìä Resultados LightGBM:\n",
        "    Train Accuracy: 0.4781\n",
        "    Test Accuracy:  0.4355\n",
        "    Overfitting:    0.0426 (ideal < 0.05)\n",
        "\n",
        "Se consigue un buen valor de test, con un Overfitting aceptable."
      ],
      "metadata": {
        "id": "psFuRRIgUop-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparacion archivo Kaggle"
      ],
      "metadata": {
        "id": "hYLtUu9V7VDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento con todo el dataset"
      ],
      "metadata": {
        "id": "IFLb1LErDPch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = lgb.Dataset(X, y - 1, categorical_feature=X.columns.tolist())\n",
        "model_final = lgb.train(\n",
        "    params, full_data,\n",
        "    num_boost_round=model.best_iteration\n",
        ")"
      ],
      "metadata": {
        "id": "SIGW-hC5G3VW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se guardan los ids de test, para al final usarlos en la creaci√≥n del archivo para la submission.\n",
        "\n",
        "En test se crea una columna que no se crea en train. Se elimina esta."
      ],
      "metadata": {
        "id": "a-eSSsD-tiKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('test.csv')\n",
        "test_ids = test.ID\n",
        "df_test = clean_saber_pro_5(test)"
      ],
      "metadata": {
        "id": "Lqepe1jd7-wb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_zUzGO7_zO1",
        "outputId": "90a26570-96fd-4ee7-8a2b-ec4fd8519873"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 296786 entries, 0 to 296785\n",
            "Data columns (total 13 columns):\n",
            " #   Column                       Non-Null Count   Dtype  \n",
            "---  ------                       --------------   -----  \n",
            " 0   E_PRGM_ACADEMICO             296786 non-null  object \n",
            " 1   E_PRGM_DEPARTAMENTO          296786 non-null  object \n",
            " 2   E_VALORMATRICULAUNIVERSIDAD  296786 non-null  object \n",
            " 3   E_HORASSEMANATRABAJA         296786 non-null  float64\n",
            " 4   F_ESTRATOVIVIENDA            296786 non-null  object \n",
            " 5   F_TIENEINTERNET              296786 non-null  object \n",
            " 6   F_EDUCACIONPADRE             296786 non-null  object \n",
            " 7   F_TIENELAVADORA              296786 non-null  object \n",
            " 8   F_TIENEAUTOMOVIL             296786 non-null  object \n",
            " 9   E_PAGOMATRICULAPROPIO        296786 non-null  object \n",
            " 10  F_TIENECOMPUTADOR            296786 non-null  object \n",
            " 11  F_EDUCACIONMADRE             296786 non-null  object \n",
            " 12  ESFUERZO_RELATIVO            296786 non-null  float64\n",
            "dtypes: float64(2), object(11)\n",
            "memory usage: 29.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convierte las columnas a categor√≠a, al igual que se hizo con el dataset de entrenamiento."
      ],
      "metadata": {
        "id": "aUX5P-1cIN76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test[X.columns]\n",
        "for col in df_test.columns:\n",
        "    df_test[col] = df_test[col].astype('category')"
      ],
      "metadata": {
        "id": "C35IOtP7amoD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUJ-_JnsIZ03",
        "outputId": "04afa9f1-84f0-471d-caf6-398fdc44c802"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 296786 entries, 0 to 296785\n",
            "Data columns (total 13 columns):\n",
            " #   Column                       Non-Null Count   Dtype   \n",
            "---  ------                       --------------   -----   \n",
            " 0   E_PRGM_ACADEMICO             296786 non-null  category\n",
            " 1   E_PRGM_DEPARTAMENTO          296786 non-null  category\n",
            " 2   E_VALORMATRICULAUNIVERSIDAD  296786 non-null  category\n",
            " 3   E_HORASSEMANATRABAJA         296786 non-null  category\n",
            " 4   F_ESTRATOVIVIENDA            296786 non-null  category\n",
            " 5   F_TIENEINTERNET              296786 non-null  category\n",
            " 6   F_EDUCACIONPADRE             296786 non-null  category\n",
            " 7   F_TIENELAVADORA              296786 non-null  category\n",
            " 8   F_TIENEAUTOMOVIL             296786 non-null  category\n",
            " 9   E_PAGOMATRICULAPROPIO        296786 non-null  category\n",
            " 10  F_TIENECOMPUTADOR            296786 non-null  category\n",
            " 11  F_EDUCACIONMADRE             296786 non-null  category\n",
            " 12  ESFUERZO_RELATIVO            296786 non-null  category\n",
            "dtypes: category(13)\n",
            "memory usage: 4.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicci√≥n"
      ],
      "metadata": {
        "id": "1KicjxBVYete"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_final = model_final.predict(df_test).argmax(axis=1) + 1"
      ],
      "metadata": {
        "id": "sCUMgtZkGHmR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pasa la variable predictora de numero a categorica"
      ],
      "metadata": {
        "id": "TruULXtth0A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {\n",
        "    1: \"bajo\",\n",
        "    2: \"medio-bajo\",\n",
        "    3: \"medio-alto\",\n",
        "    4: \"alto\"\n",
        "}\n",
        "\n",
        "pred_str = pd.Series(y_pred_final).map(mapping).to_numpy()"
      ],
      "metadata": {
        "id": "KRuQdNSNSXLX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVOolCOWUJxs",
        "outputId": "f8056b1c-8792-48a1-e9f0-48ef72712a0a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['bajo', 'medio-bajo', 'alto', ..., 'medio-alto', 'alto', 'alto'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generaci√≥n de archivo"
      ],
      "metadata": {
        "id": "s8BkMKKa7lxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': pred_str\n",
        "})\n",
        "\n",
        "submission.to_csv('saber_pro_2025-2_submission-99.csv', index=False)"
      ],
      "metadata": {
        "id": "ah54eCBF7ocI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head saber_pro_2025-2_submission-99.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRht9DWRVL9U",
        "outputId": "32c82d14-1f4b-4e07-dbd2-dd58e7d19e2c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID,RENDIMIENTO_GLOBAL\n",
            "550236,bajo\n",
            "98545,medio-bajo\n",
            "499179,alto\n",
            "782980,bajo\n",
            "785185,bajo\n",
            "58495,bajo\n",
            "705444,alto\n",
            "557548,alto\n",
            "519909,bajo\n"
          ]
        }
      ]
    }
  ]
}